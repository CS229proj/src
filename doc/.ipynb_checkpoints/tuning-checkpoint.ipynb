{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from passage.models import RNN\n",
    "from passage.updates import Adadelta\n",
    "from passage.updates import NAG, Regularizer\n",
    "from passage.layers import Embedding, GatedRecurrent, Dense\n",
    "from passage.preprocessing import *\n",
    "\n",
    "from sklearn import preprocessing, metrics\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = '../../devel.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_data = pd.read_csv(fn, encoding='utf-8', sep=r'\\t+', header=None, names=['text', 'label'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grps = tr_data.groupby(['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bg (2000, 2)\n",
      "bs (2000, 2)\n",
      "cz (2000, 2)\n",
      "es-AR (2000, 2)\n",
      "es-ES (2000, 2)\n",
      "hr (2000, 2)\n",
      "id (2000, 2)\n",
      "mk (2000, 2)\n",
      "my (2000, 2)\n",
      "pt-BR (2000, 2)\n",
      "pt-PT (2000, 2)\n",
      "sk (2000, 2)\n",
      "sr (2000, 2)\n",
      "xx (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(columns=['text','label'])\n",
    "test_df = pd.DataFrame(columns=['text','label'])\n",
    "\n",
    "for name, grp in grps:\n",
    "    print name, grp.shape\n",
    "    train, test = train_test_split(grp, test_size=0.25, random_state=42)\n",
    "\n",
    "    train_df = train_df.append(train, ignore_index=True)\n",
    "    test_df = test_df.append(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX = train_df['text'].values\n",
    "trY = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teX = test_df['text'].values\n",
    "teY = test_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bg', 'bs', 'cz', 'es-AR', 'es-ES', 'hr', 'id', 'mk', 'my', 'pt-BR',\n",
       "       'pt-PT', 'sk', 'sr', 'xx'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "trY_t = le.fit_transform(trY)\n",
    "teY_t = le.transform(teY)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data tokenized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Downloads/passage/passage/preprocessing.py:41: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if t in punctuation:\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(min_df=1, max_features=1000000)\n",
    "trX_t = tokenizer.fit_transform(trX)\n",
    "print(\"Training data tokenized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149110"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teX_t = tokenizer.transform(teX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Seen 20792 samples Avg cost 2.4355 Time elapsed 44 seconds\n",
      "Epoch 1 Seen 41584 samples Avg cost 1.2924 Time elapsed 89 seconds\n",
      "Epoch 2 Seen 62376 samples Avg cost 0.7769 Time elapsed 134 seconds\n",
      "Epoch 3 Seen 83168 samples Avg cost 0.5896 Time elapsed 179 seconds\n",
      "Epoch 4 Seen 103960 samples Avg cost 0.5007 Time elapsed 224 seconds\n",
      "Epoch 5 Seen 124752 samples Avg cost 0.4535 Time elapsed 269 seconds\n",
      "Epoch 6 Seen 145544 samples Avg cost 0.4182 Time elapsed 314 seconds\n",
      "Epoch 7 Seen 166336 samples Avg cost 0.3604 Time elapsed 359 seconds\n",
      "Epoch 8 Seen 187128 samples Avg cost 0.2925 Time elapsed 404 seconds\n",
      "Epoch 9 Seen 207920 samples Avg cost 0.2367 Time elapsed 449 seconds\n",
      "Epoch 0 Seen 20792 samples Avg cost 2.4850 Time elapsed 45 seconds\n",
      "Epoch 1 Seen 41584 samples Avg cost 1.2592 Time elapsed 90 seconds\n",
      "Epoch 2 Seen 62376 samples Avg cost 0.7700 Time elapsed 135 seconds\n",
      "Epoch 3 Seen 83168 samples Avg cost 0.6119 Time elapsed 180 seconds\n",
      "Epoch 4 Seen 103960 samples Avg cost 0.5005 Time elapsed 225 seconds\n",
      "Epoch 5 Seen 124752 samples Avg cost 0.4450 Time elapsed 270 seconds\n",
      "Epoch 6 Seen 145544 samples Avg cost 0.4097 Time elapsed 315 seconds\n",
      "Epoch 7 Seen 166336 samples Avg cost 0.3500 Time elapsed 360 seconds\n",
      "Epoch 8 Seen 187128 samples Avg cost 0.2870 Time elapsed 405 seconds\n",
      "Epoch 9 Seen 207920 samples Avg cost 0.2245 Time elapsed 450 seconds\n",
      "Epoch 0 Seen 20792 samples Avg cost 2.4716 Time elapsed 44 seconds\n",
      "Epoch 1 Seen 41584 samples Avg cost 1.2705 Time elapsed 90 seconds\n",
      "Epoch 2 Seen 62376 samples Avg cost 0.8024 Time elapsed 134 seconds\n",
      "Epoch 3 Seen 83168 samples Avg cost 0.5743 Time elapsed 179 seconds\n",
      "Epoch 4 Seen 103960 samples Avg cost 0.4874 Time elapsed 224 seconds\n",
      "Epoch 5 Seen 124752 samples Avg cost 0.4568 Time elapsed 269 seconds\n",
      "Epoch 6 Seen 145544 samples Avg cost 0.4168 Time elapsed 314 seconds\n",
      "Epoch 7 Seen 166336 samples Avg cost 0.3700 Time elapsed 359 seconds\n",
      "Epoch 8 Seen 187128 samples Avg cost 0.3269 Time elapsed 404 seconds\n",
      "Epoch 9 Seen 207920 samples Avg cost 0.2665 Time elapsed 449 seconds\n",
      "Epoch 0 Seen 20792 samples Avg cost 2.4095 Time elapsed 45 seconds\n",
      "Epoch 1 Seen 41584 samples Avg cost 1.1314 Time elapsed 90 seconds\n",
      "Epoch 2 Seen 62376 samples Avg cost 0.7480 Time elapsed 135 seconds\n",
      "Epoch 3 Seen 83168 samples Avg cost 0.5474 Time elapsed 180 seconds\n",
      "Epoch 4 Seen 103960 samples Avg cost 0.4872 Time elapsed 225 seconds\n",
      "Epoch 5 Seen 124752 samples Avg cost 0.4350 Time elapsed 270 seconds\n",
      "Epoch 6 Seen 145544 samples Avg cost 0.3889 Time elapsed 315 seconds\n",
      "Epoch 7 Seen 166336 samples Avg cost 0.3319 Time elapsed 360 seconds\n",
      "Epoch 8 Seen 187128 samples Avg cost 0.2815 Time elapsed 406 seconds\n",
      "Epoch 9 Seen 207920 samples Avg cost 0.2358 Time elapsed 451 seconds\n",
      "Epoch 0 Seen 20792 samples Avg cost 2.4982 Time elapsed 45 seconds\n",
      "Epoch 1 Seen 41584 samples Avg cost 1.2589 Time elapsed 90 seconds\n",
      "Epoch 2 Seen 62376 samples Avg cost 0.8211 Time elapsed 135 seconds\n",
      "Epoch 3 Seen 83168 samples Avg cost 0.6269 Time elapsed 180 seconds\n",
      "Epoch 4 Seen 103960 samples Avg cost 0.5278 Time elapsed 225 seconds\n",
      "Epoch 5 Seen 124752 samples Avg cost 0.4625 Time elapsed 270 seconds\n",
      "Epoch 6 Seen 145544 samples Avg cost 0.4531 Time elapsed 315 seconds\n",
      "Epoch 7 Seen 166336 samples Avg cost 0.3882 Time elapsed 361 seconds\n",
      "Epoch 8 Seen 187128 samples Avg cost 0.3393 Time elapsed 406 seconds\n",
      "Epoch 9 Seen 207920 samples Avg cost 0.2787 Time elapsed 451 seconds\n",
      "Epoch 0 Seen 20792 samples Avg cost 2.4161 Time elapsed 45 seconds\n",
      "Epoch 1 Seen 41584 samples Avg cost 1.1996 Time elapsed 90 seconds\n",
      "Epoch 2 Seen 62376 samples Avg cost 0.7403 Time elapsed 135 seconds\n",
      "Epoch 3 Seen 83168 samples Avg cost 0.5696 Time elapsed 181 seconds\n",
      "Epoch 4 Seen 103960 samples Avg cost 0.5025 Time elapsed 226 seconds\n",
      "Epoch 5 Seen 124752 samples Avg cost 0.4631 Time elapsed 271 seconds\n",
      "Epoch 6 Seen 145544 samples Avg cost 0.4309 Time elapsed 317 seconds\n",
      "Epoch 7 Seen 159688 samples Avg cost 0.3883 Time left 14 seconds"
     ]
    }
   ],
   "source": [
    "p_drop_scores = {}\n",
    "\n",
    "for p_drop in [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45]:\n",
    "    layers = [\n",
    "        Embedding(size=128, n_features=tokenizer.n_features),\n",
    "        GatedRecurrent(size=768, p_drop=p_drop),\n",
    "        Dense(size=14, activation='softmax', p_drop=0.2)\n",
    "    ]\n",
    "\n",
    "    model = RNN(layers=layers, cost='cce', updater=Adadelta(lr=0.5))\n",
    "    model.fit(trX_t, trY_t, n_epochs=10)\n",
    "\n",
    "    pr_teX = model.predict(teX_t)\n",
    "    classes = np.argmax(pr_teX, axis=1)\n",
    "\n",
    "    acc = metrics.accuracy_score(teY_t, classes)\n",
    "    p_drop_scores[p_drop] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = zip(*size_scores.iteritems())\n",
    "plt.scatter(scores[0], scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = zip(*p_drop_scores.iteritems())\n",
    "plt.scatter(scores[0], scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_scores = {}\n",
    "\n",
    "for epoch in [5, 7, 10, 13, 15, 17, 20, 22, 25]:\n",
    "    layers = [\n",
    "        Embedding(size=128, n_features=tokenizer.n_features),\n",
    "        GatedRecurrent(size=768, p_drop=0.4),\n",
    "        Dense(size=14, activation='softmax', p_drop=0.2)\n",
    "    ]\n",
    "\n",
    "    model = RNN(layers=layers, cost='cce', updater=Adadelta(lr=0.5))\n",
    "    model.fit(trX_t, trY_t, n_epochs=epoch)\n",
    "\n",
    "    pr_teX = model.predict(teX_t)\n",
    "    classes = np.argmax(pr_teX, axis=1)\n",
    "\n",
    "    acc = metrics.accuracy_score(teY_t, classes)\n",
    "    epochs_scores[epoch] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = zip(*epochs_scores.iteritems())\n",
    "plt.scatter(scores[0], scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
