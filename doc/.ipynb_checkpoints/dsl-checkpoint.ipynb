{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lxml import html\n",
    "from itertools import izip, chain,islice\n",
    "\n",
    "from passage.models import RNN\n",
    "from passage.updates import Adadelta\n",
    "from passage.updates import NAG, Regularizer\n",
    "from passage.layers import Embedding, GatedRecurrent, Dense\n",
    "from passage.preprocessing import *\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharTokenize(Tokenizer):\n",
    "    def __init__(self, max_features=9997, min_df=10, lowercase=True, character=False, charn=1):\n",
    "        super(CharTokenize, self).__init__(max_features, min_df, lowercase, character)\n",
    "        self.charn = charn\n",
    "        \n",
    "    def ntuples(self, lst, n):\n",
    "        iters = izip(*[chain(islice(lst,i,None)) for i in range(n)])\n",
    "        return [''.join(i) for i in iters]\n",
    "    \n",
    "    def fit(self, texts):\n",
    "        if self.lowercase:\n",
    "            texts = [text.lower() for text in texts]\n",
    "        if self.character:\n",
    "            tokens = [self.ntuples(list(text.decode(\"utf-8\")), self.charn) for text in texts]\n",
    "#             print tokens\n",
    "        else:\n",
    "            tokens = [tokenize(text) for text in texts]\n",
    "        self.encoder = token_encoder(tokens, max_features=self.max_features-3, min_df=self.min_df)\n",
    "        self.encoder['PAD'] = 0\n",
    "        self.encoder['END'] = 1\n",
    "        self.encoder['UNK'] = 2\n",
    "        self.decoder = dict(zip(self.encoder.values(), self.encoder.keys()))\n",
    "        self.n_features = len(self.encoder)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, texts):\n",
    "        if self.lowercase:\n",
    "            texts = [text.lower() for text in texts]\n",
    "        if self.character:\n",
    "            texts = [self.ntuples(list(text.decode(\"utf-8\")), self.charn) for text in texts]\n",
    "        else:\n",
    "            texts = [tokenize(text) for text in texts]\n",
    "        tokens = [[self.encoder.get(token, 2) for token in text] for text in texts]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFile = \"../../train.txt\"\n",
    "testFile = \"../../test.txt\"\n",
    "goldFile = \"../../test-gold.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "tr_data = pd.read_csv(trainFile, encoding='utf-8', sep=r'\\t+', header=None, names=['text', 'label'])\n",
    "trX = tr_data['text'].values\n",
    "trY = tr_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data['text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bg', 'bs', 'cz', 'es-AR', 'es-ES', 'hr', 'id', 'mk', 'my', 'pt-BR',\n",
       "       'pt-PT', 'sk', 'sr', 'xx'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "trY_t = le.fit_transform(trY)\n",
    "le.classes_\n",
    "# trY_t.dtype = np.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data tokenized.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CharTokenize(character=True, charn=4, min_df=2, max_features=1000000)\n",
    "trX_t = tokenizer.fit_transform(trX)\n",
    "print(\"Training data tokenized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372308"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "te_data = pd.read_csv(testFile, encoding='utf-8', sep=r'\\t+', header=None, names=['text'])\n",
    "teX = te_data['text'].values\n",
    "# teX_t = tokenizer.transform(teX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# layers = [\n",
    "#     Embedding(size=128, n_features=tokenizer.n_features),\n",
    "#     GatedRecurrent(size=512, p_drop=0.4),\n",
    "#     Dense(size=14, activation='softmax', p_drop=0.2)\n",
    "# ]\n",
    "\n",
    "# model = RNN(layers=layers, cost='cce', updater=Adadelta(lr=0.5))\n",
    "# model.fit(trX_t, trY_t, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993869047619\n"
     ]
    }
   ],
   "source": [
    "pr_trX = model.predict(trX_t)\n",
    "print(np.mean(trY_t == np.argmax(pr_trX, axis=1)))\n",
    "\n",
    "pr_teX = model.predict(teX_t)\n",
    "classes = np.argmax(pr_teX, axis=1)\n",
    "\n",
    "te_data['classes'] = le.inverse_transform(classes)\n",
    "te_data.head()\n",
    "\n",
    "gold_output = 'RNN_LSTM_1L.txt'\n",
    "te_data.to_csv(gold_output, sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results === \r\n",
      "\r\n",
      "Portugese\r\n",
      "pt-BR: 848 / 1000 = 0.848\r\n",
      "pt-PT: 943 / 1000 = 0.943\r\n",
      "\r\n",
      "Bulgarian, Macedonian\r\n",
      "bg: 1000 / 1000 = 1.0\r\n",
      "mk: 998 / 1000 = 0.998\r\n",
      "\r\n",
      "Spanish\r\n",
      "es-ES: 855 / 1000 = 0.855\r\n",
      "es-AR: 889 / 1000 = 0.889\r\n",
      "\r\n",
      "Bosnian, Croatian, Serbian\r\n",
      "bs: 807 / 1000 = 0.807\r\n",
      "hr: 913 / 1000 = 0.913\r\n",
      "sr: 921 / 1000 = 0.921\r\n",
      "\r\n",
      "Malay, Indo\r\n",
      "my: 981 / 1000 = 0.981\r\n",
      "id: 984 / 1000 = 0.984\r\n",
      "\r\n",
      "Czech, Slovak\r\n",
      "cz: 983 / 1000 = 0.983\r\n",
      "sk: 1000 / 1000 = 1.0\r\n",
      "\r\n",
      "Others\r\n",
      "xx: 992 / 1000 = 0.992\r\n",
      "\r\n",
      "Overall: 13114 / 14000 = 0.936714285714\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../evaluate.py RNN_LSTM_1L.txt ../../test-gold.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##3 grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer3 = CharTokenize(character=True, charn=3, min_df=1, max_features=1000000)\n",
    "trX_t3 = tokenizer3.fit_transform(trX)\n",
    "teX_t3 = tokenizer3.transform(teX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Seen 5184 samples Avg cost 2.6376 Time left 1536 seconds"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    Embedding(size=128, n_features=tokenizer3.n_features),\n",
    "    GatedRecurrent(size=512, p_drop=0.4),\n",
    "    Dense(size=14, activation='softmax', p_drop=0.2)\n",
    "]\n",
    "\n",
    "model3 = RNN(layers=layers, cost='cce', updater=Adadelta(lr=0.5))\n",
    "model3.fit(trX_t3, trY_t, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr_trX3 = model3.predict(trX_t3)\n",
    "print(np.mean(trY_t == np.argmax(pr_trX3, axis=1)))\n",
    "\n",
    "pr_teX3 = model3.predict(teX_t3)\n",
    "classes = np.argmax(pr_teX3, axis=1)\n",
    "\n",
    "te_data['classes'] = le.inverse_transform(classes)\n",
    "te_data.head()\n",
    "\n",
    "gold_output = 'RNN_LSTM_C3G.txt'\n",
    "te_data.to_csv(gold_output, sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results === \r\n",
      "\r\n",
      "Portugese\r\n",
      "pt-BR: 903 / 1000 = 0.903\r\n",
      "pt-PT: 882 / 1000 = 0.882\r\n",
      "\r\n",
      "Bulgarian, Macedonian\r\n",
      "bg: 1000 / 1000 = 1.0\r\n",
      "mk: 1000 / 1000 = 1.0\r\n",
      "\r\n",
      "Spanish\r\n",
      "es-ES: 830 / 1000 = 0.83\r\n",
      "es-AR: 902 / 1000 = 0.902\r\n",
      "\r\n",
      "Bosnian, Croatian, Serbian\r\n",
      "bs: 837 / 1000 = 0.837\r\n",
      "hr: 850 / 1000 = 0.85\r\n",
      "sr: 930 / 1000 = 0.93\r\n",
      "\r\n",
      "Malay, Indo\r\n",
      "my: 946 / 1000 = 0.946\r\n",
      "id: 985 / 1000 = 0.985\r\n",
      "\r\n",
      "Czech, Slovak\r\n",
      "cz: 997 / 1000 = 0.997\r\n",
      "sk: 995 / 1000 = 0.995\r\n",
      "\r\n",
      "Others\r\n",
      "xx: 998 / 1000 = 0.998\r\n",
      "\r\n",
      "Overall: 13055 / 14000 = 0.9325\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../evaluate.py RNN_LSTM_C3G.txt ../../test-gold.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer2 = CharTokenize(character=True, charn=2, min_df=1, max_features=1000000)\n",
    "trX_t2 = tokenizer2.fit_transform(trX)\n",
    "teX_t2 = tokenizer2.transform(teX)\n",
    "\n",
    "print tokenizer2.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Seen 47424 samples Avg cost 1.3115 Time left 1271 seconds"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    Embedding(size=128, n_features=tokenizer2.n_features),\n",
    "    GatedRecurrent(size=512, p_drop=0.4),\n",
    "    Dense(size=14, activation='softmax', p_drop=0.2)\n",
    "]\n",
    "\n",
    "model2 = RNN(layers=layers, cost='cce', updater=Adadelta(lr=0.5))\n",
    "model2.fit(trX_t2, trY_t, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr_trX2 = model2.predict(trX_t2)\n",
    "print(np.mean(trY_t == np.argmax(pr_trX2, axis=1)))\n",
    "\n",
    "pr_teX2 = model2.predict(teX_t2)\n",
    "classes = np.argmax(pr_teX2, axis=1)\n",
    "\n",
    "te_data['classes'] = le.inverse_transform(classes)\n",
    "te_data.head()\n",
    "\n",
    "gold_output = 'RNN_LSTM_C2G.txt'\n",
    "te_data.to_csv(gold_output, sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python ../../evaluate.py RNN_LSTM_C2G.txt ../../test-gold.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##5 grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer5 = CharTokenize(character=True, charn=5, min_df=2, max_features=1000000)\n",
    "trX_t5 = tokenizer5.fit_transform(trX)\n",
    "teX_t5 = tokenizer5.transform(teX)\n",
    "\n",
    "print tokenizer5.n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Seen 249520 samples Avg cost 0.4232 Time elapsed 1861 seconds\n",
      "Epoch 1 Seen 499040 samples Avg cost 0.2166 Time elapsed 3724 seconds\n",
      "Epoch 2 Seen 500896 samples Avg cost 0.1589 Time left 1848 seconds"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    Embedding(size=128, n_features=tokenizer5.n_features),\n",
    "    GatedRecurrent(size=512, p_drop=0.4),\n",
    "    Dense(size=14, activation='softmax', p_drop=0.2)\n",
    "]\n",
    "\n",
    "model5 = RNN(layers=layers, cost='cce', updater=Adadelta(lr=0.5))\n",
    "model5.fit(trX_t5, trY_t, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr_trX5 = model5.predict(trX_t5)\n",
    "print(np.mean(trY_t == np.argmax(pr_trX5, axis=1)))\n",
    "\n",
    "pr_teX5 = model5.predict(teX_t5)\n",
    "classes = np.argmax(pr_teX5, axis=1)\n",
    "\n",
    "te_data['classes'] = le.inverse_transform(classes)\n",
    "te_data.head()\n",
    "\n",
    "gold_output = 'RNN_LSTM_C5G.txt'\n",
    "te_data.to_csv(gold_output, sep='\\t', index=False, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python ../../evaluate.py RNN_LSTM_C5G.txt ../../test-gold.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getY(fl):\n",
    "    data = pd.read_csv(fl, encoding='utf-8', sep=r'\\t+', header=None, names=['text', 'label'])\n",
    "    trY = data['label'].values\n",
    "    return trY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# classes4 = np.argmax(pr_teX, axis=1)\n",
    "\n",
    "# classes3 = np.argmax(pr_teX3, axis=1)\n",
    "\n",
    "# classes2 = np.argmax(pr_teX2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "c2g = getY('RNN_LSTM_C2G.txt')\n",
    "c3g = getY('RNN_LSTM_C3G.txt')\n",
    "c4g = getY('RNN_LSTM_1L.txt')\n",
    "c5g = getY('RNN_LSTM_C5G.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = zip(c5g, c5g, c3g, c4g, c2g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = map(lambda x: most_common(x), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "te_data['classes'] = preds\n",
    "\n",
    "gold_output = 'RNN_LSTM_ensemble.txt'\n",
    "te_data.to_csv(gold_output, sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results === \r\n",
      "\r\n",
      "Portugese\r\n",
      "pt-BR: 945 / 1000 = 0.945\r\n",
      "pt-PT: 878 / 1000 = 0.878\r\n",
      "\r\n",
      "Bulgarian, Macedonian\r\n",
      "bg: 1000 / 1000 = 1.0\r\n",
      "mk: 999 / 1000 = 0.999\r\n",
      "\r\n",
      "Spanish\r\n",
      "es-ES: 849 / 1000 = 0.849\r\n",
      "es-AR: 926 / 1000 = 0.926\r\n",
      "\r\n",
      "Bosnian, Croatian, Serbian\r\n",
      "bs: 823 / 1000 = 0.823\r\n",
      "hr: 893 / 1000 = 0.893\r\n",
      "sr: 967 / 1000 = 0.967\r\n",
      "\r\n",
      "Malay, Indo\r\n",
      "my: 987 / 1000 = 0.987\r\n",
      "id: 986 / 1000 = 0.986\r\n",
      "\r\n",
      "Czech, Slovak\r\n",
      "cz: 997 / 1000 = 0.997\r\n",
      "sk: 1000 / 1000 = 1.0\r\n",
      "\r\n",
      "Others\r\n",
      "xx: 1000 / 1000 = 1.0\r\n",
      "\r\n",
      "Overall: 13250 / 14000 = 0.946428571429\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python ../../evaluate.py RNN_LSTM_ensemble.txt ../../test-gold.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
